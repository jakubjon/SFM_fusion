"""
Step 7: Generate high resolution orthorectified images individual pictures for ROI
"""

import cv2
import numpy as np
from pathlib import Path
from datetime import datetime
from step_base import StepBase
import config
import pycolmap


class HighResRectificationStep(StepBase):
    """Step 7: High resolution rectification for ROI"""
    
    def __init__(self, photos_dir=config.PHOTOS_DIR, output_dir=config.OUTPUT_DIR):
        super().__init__(output_dir)
        self.photos_dir = Path(photos_dir)
        self.painting_sets = [d for d in self.photos_dir.iterdir() if d.is_dir()]
        self.high_res_dir = self.output_dir / 'high_res_rectified'
        self.high_res_dir.mkdir(exist_ok=True)
    
    def get_input_requirements(self):
        """Return required inputs for this step"""
        return [
            "step3_recalculate_positions_results",
            "step4_point_cloud_results",
            "step6_roi_selection_results"
        ]
    
    def get_output_files(self):
        """Return output files generated by this step"""
        outputs = []
        for painting_set in self.painting_sets:
            painting_name = painting_set.name
            outputs.extend([
                f"high_res_rectified/{painting_name}_high_res_*.jpg",
                f"intermediate/high_res_rectification_data_{painting_name}.json"
            ])
        outputs.append("intermediate/step7_high_res_rectification_results.json")
        return outputs
    
    def qvec2rotmat(self, qvec):
        """Convert quaternion to rotation matrix"""
        w, x, y, z = qvec
        return np.array([
            [1 - 2*y**2 - 2*z**2, 2*x*y - 2*z*w, 2*x*z + 2*y*w],
            [2*x*y + 2*z*w, 1 - 2*x**2 - 2*z**2, 2*y*z - 2*x*w],
            [2*x*z - 2*y*w, 2*y*z + 2*x*w, 1 - 2*x**2 - 2*y**2]
        ])
    
    def rectify_image_high_res(self, image_path, pose_data, K, plane_normal, plane_center, 
                              roi_bounds, painting_name, target_resolution=2048):
        """High resolution rectification for ROI using proper 2D coordinate system"""
        # Load the image
        img = cv2.imread(str(image_path))
        if img is None:
            print(f"Could not load image: {image_path}")
            return None
        
        # Extract pose information
        if not pose_data:
            print(f"No pose data available for {image_path.name}")
            return None
        
        # Create camera projection matrix
        rotation_matrix = np.array(pose_data['rotation_matrix'])
        translation = np.array(pose_data['translation'])
        
        # Create pose matrix
        pose = np.eye(4)
        pose[:3, :3] = rotation_matrix
        pose[:3, 3] = translation
        
        # Create camera projection matrix
        P = K @ pose[:3]  # camera projection matrix

        # Step 1: Create 2D coordinate system on the painting plane
        # Create two vectors perpendicular to the normal
        if abs(plane_normal[0]) < 0.9:
            v1 = np.array([1, 0, 0])
        else:
            v1 = np.array([0, 1, 0])
        v2 = np.cross(plane_normal, v1)
        v1 = np.cross(v2, plane_normal)
        
        # Normalize
        v1 = v1 / np.linalg.norm(v1)
        v2 = v2 / np.linalg.norm(v2)
        
        # Step 2: Load 3D points from COLMAP reconstruction
        reconstruction_path = self.output_dir / painting_name / 'global' / '0'
        if not reconstruction_path.exists():
            print(f"[ERROR] COLMAP reconstruction not found for {painting_name}")
            return None
        
        try:
            # Load the reconstruction
            reconstruction = pycolmap.Reconstruction(str(reconstruction_path))
            points3D = reconstruction.points3D
            
            if len(points3D) < 10:
                print(f"Not enough 3D points for high-res rectification: {image_path.name}")
                return None
            
            # Extract 3D point coordinates
            points3D_coords = []
            for point3D in points3D.values():
                points3D_coords.append(point3D.xyz)
            
            points3D_coords = np.array(points3D_coords)
            
            # Step 3: Project all 3D points to the 2D coordinate system
            points_2d_plane = []
            for point_3d in points3D_coords:
                # Vector from plane center to point
                vec = point_3d - plane_center
                
                # Project to 2D coordinate system
                u = np.dot(vec, v1)
                v = np.dot(vec, v2)
                points_2d_plane.append([u, v])
            
            points_2d_plane = np.array(points_2d_plane)
            
            # Step 4: Find the full painting bounds (same as low-res rectification)
            min_u, min_v = points_2d_plane.min(axis=0)
            max_u, max_v = points_2d_plane.max(axis=0)
            
            # Add margin (same as low-res rectification)
            margin = config.RECTIFICATION_CONFIG['envelope_margin']
            u_range = max_u - min_u
            v_range = max_v - min_v
            min_u -= u_range * margin
            max_u += u_range * margin
            min_v -= v_range * margin
            max_v += v_range * margin
            
            # Step 5: Map ROI bounds from overview to 2D plane coordinates
            # The overview image was created with a specific grid size (config.GRID_SIZE // 2)
            overview_grid_size = config.GRID_SIZE // 2  # This is 256
            
            # Extract ROI bounds from the overview image
            roi_x_min = roi_bounds['x_min']
            roi_x_max = roi_bounds['x_max']
            roi_y_min = roi_bounds['y_min']
            roi_y_max = roi_bounds['y_max']
            
            # Map ROI coordinates from overview image pixels to 2D plane coordinates
            # Calculate the step size in 2D plane coordinates per overview pixel
            u_step = (max_u - min_u) / (overview_grid_size - 1)
            v_step = (max_v - min_v) / (overview_grid_size - 1)
            
            # Map ROI pixel coordinates to 2D plane coordinates
            roi_min_u = min_u + roi_x_min * u_step
            roi_max_u = min_u + roi_x_max * u_step
            roi_min_v = min_v + roi_y_min * v_step
            roi_max_v = min_v + roi_y_max * v_step
            
            # Step 6: Create high resolution grid for the FULL painting area (same as Step 5)
            # Use a larger grid size for high resolution
            full_grid_size = target_resolution * 2  # Create larger grid to ensure ROI is covered
            rectified_points_3d = []
            
            for i in range(full_grid_size):
                for j in range(full_grid_size):
                    # Map grid coordinates to full painting coordinates (same as Step 5)
                    u = min_u + (i / (full_grid_size - 1)) * (max_u - min_u)
                    v = min_v + (j / (full_grid_size - 1)) * (max_v - min_v)
                    
                    # Convert back to 3D
                    point_3d = plane_center + u * v1 + v * v2
                    rectified_points_3d.append(point_3d)
            
            rectified_points_3d = np.array(rectified_points_3d)
            
            # Step 7: Project rectified points to image (same as Step 5)
            src_points = []
            dst_points = []
            
            for i, point_3d in enumerate(rectified_points_3d):
                point_homo = np.append(point_3d, 1)
                point_img = P @ point_homo
                point_img = point_img[:2] / point_img[2]
                
                # Check if point is in image bounds
                if (0 <= point_img[0] < img.shape[1] and 
                    0 <= point_img[1] < img.shape[0]):
                    src_points.append(point_img)
                    # Map to rectified coordinates
                    dst_points.append([i % full_grid_size, i // full_grid_size])
            
            if len(src_points) < 4:
                print(f"Not enough valid points for high-res rectification: {image_path.name}")
                return None
            
            src_points = np.array(src_points, dtype=np.float32)
            dst_points = np.array(dst_points, dtype=np.float32)
            
            # Step 8: Compute homography and apply rectification (same as Step 5)
            H = cv2.findHomography(src_points, dst_points)[0]
            full_rectified = cv2.warpPerspective(img, H, (full_grid_size, full_grid_size))
            
            # Step 9: Crop the full rectified image to ROI area
            # Map ROI bounds to the full grid coordinates
            roi_min_i = int((roi_min_u - min_u) / (max_u - min_u) * (full_grid_size - 1))
            roi_max_i = int((roi_max_u - min_u) / (max_u - min_u) * (full_grid_size - 1))
            roi_min_j = int((roi_min_v - min_v) / (max_v - min_v) * (full_grid_size - 1))
            roi_max_j = int((roi_max_v - min_v) / (max_v - min_v) * (full_grid_size - 1))
            
            # Ensure bounds are within the full grid
            roi_min_i = max(0, min(full_grid_size - 1, roi_min_i))
            roi_max_i = max(0, min(full_grid_size - 1, roi_max_i))
            roi_min_j = max(0, min(full_grid_size - 1, roi_min_j))
            roi_max_j = max(0, min(full_grid_size - 1, roi_max_j))
            
            # Crop to ROI
            roi_rectified = full_rectified[roi_min_j:roi_max_j+1, roi_min_i:roi_max_i+1]
            
            # Resize to target resolution if needed
            if roi_rectified.shape[0] != target_resolution or roi_rectified.shape[1] != target_resolution:
                roi_rectified = cv2.resize(roi_rectified, (target_resolution, target_resolution))
            
            # Debug: Print ROI mapping information
            print(f"  ROI overview coords: ({roi_x_min}, {roi_y_min}) to ({roi_x_max}, {roi_y_max})")
            print(f"  ROI plane coords: ({roi_min_u:.4f}, {roi_min_v:.4f}) to ({roi_max_u:.4f}, {roi_max_v:.4f})")
            print(f"  ROI grid coords: ({roi_min_i}, {roi_min_j}) to ({roi_max_i}, {roi_max_j})")
            print(f"  Full grid size: {full_grid_size}x{full_grid_size}")
            print(f"  ROI crop size: {roi_rectified.shape[1]}x{roi_rectified.shape[0]}")
            print(f"  Output resolution: {target_resolution}x{target_resolution}")
            
            return roi_rectified
            
        except Exception as e:
            print(f"[ERROR] Failed to load reconstruction for {painting_name}: {e}")
            return None
    
    def apply_enhancement(self, image):
        """Apply image enhancement for high resolution output"""
        # Check if image has alpha channel (BGRA)
        if len(image.shape) == 3 and image.shape[2] == 4:
            # Extract BGR channels for enhancement
            bgr = image[:, :, :3]
            alpha = image[:, :, 3]
            
            # Convert to LAB color space
            lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)
            
            # Apply CLAHE to L channel
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            lab[:, :, 0] = clahe.apply(lab[:, :, 0])
            
            # Convert back to BGR
            enhanced_bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
            
            # Apply sharpening
            kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])
            enhanced_bgr = cv2.filter2D(enhanced_bgr, -1, kernel)
            
            # Reconstruct BGRA image
            enhanced = np.zeros((image.shape[0], image.shape[1], 4), dtype=np.uint8)
            enhanced[:, :, :3] = enhanced_bgr
            enhanced[:, :, 3] = alpha
            
            return enhanced
        else:
            # Handle regular BGR images
            # Convert to LAB color space
            lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
            
            # Apply CLAHE to L channel
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            lab[:, :, 0] = clahe.apply(lab[:, :, 0])
            
            # Convert back to BGR
            enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
            
            # Apply sharpening
            kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])
            enhanced = cv2.filter2D(enhanced, -1, kernel)
            
            return enhanced
    
    def run(self, **kwargs):
        """
        Generate high resolution orthorectified images for ROI.
        
        Returns:
            dict: Results containing high resolution rectification data
        """
        self.log_step("Step 7: High resolution rectification for ROI")
        
        # Load global reconstructions from Step 3
        step3_results = self.load_result("step3_recalculate_positions_results")
        if not step3_results:
            print("[ERROR] Step 3 results not found. Please run Step 3 first.")
            return None
        
        global_reconstructions = step3_results.get('global_reconstructions', {})
        global_camera_params = step3_results.get('global_camera_params')
        
        if not global_reconstructions:
            print("[ERROR] No global reconstructions found in Step 3 results.")
            return None
        
        # Load point cloud data from Step 4
        step4_results = self.load_result("step4_point_cloud_results")
        if not step4_results:
            print("[ERROR] Step 4 results not found. Please run Step 4 first.")
            return None
        
        point_cloud_data = step4_results.get('point_cloud_data', {})
        
        # Load ROI selections from Step 6
        step6_results = self.load_result("step6_roi_selection_results")
        if not step6_results:
            print("[ERROR] Step 6 results not found. Please run Step 6 first.")
            return None
        
        roi_selections = step6_results.get('roi_selections', {})
        
        high_res_results = {}
        
        for painting_set in self.painting_sets:
            painting_name = painting_set.name
            print(f"\n{'='*80}")
            print(f"High resolution rectification for painting {painting_name}")
            print(f"{'='*80}")
            
            # Check if we already have high res rectification data
            existing_result = self.load_result(f"high_res_rectification_data_{painting_name}")
            if existing_result and config.INTERMEDIATE_RESULTS['save_intermediate'] and not self.should_overwrite_existing():
                print(f"Found existing high res rectification data for {painting_name}")
                high_res_results[painting_name] = existing_result
                continue
            
            # Get reconstruction data
            reconstruction_data = global_reconstructions.get(painting_name)
            if not reconstruction_data:
                print(f"[ERROR] No reconstruction data found for {painting_name}")
                continue
            
            # Get point cloud data for plane information
            point_cloud_info = point_cloud_data.get(painting_name, {})
            plane_data = point_cloud_info.get('plane_data', {})
            
            # Get ROI selection
            roi_data = roi_selections.get(painting_name)
            if not roi_data:
                print(f"[ERROR] No ROI selection found for {painting_name}")
                continue
            
            roi_bounds = roi_data.get('roi_bounds', {})
            if not roi_bounds:
                print(f"[ERROR] No ROI bounds found for {painting_name}")
                continue
            
            # Extract camera intrinsics from global calibration
            if isinstance(global_camera_params, dict):
                params = global_camera_params['params']
                if len(params) >= 4:  # SIMPLE_RADIAL has 4 parameters
                    fx, cx, cy, k1 = params[:4]
                    K = np.array([[fx, 0, cx], [0, fx, cy], [0, 0, 1]])
                    print(f"Using global calibration: focal_length={fx:.2f}, k1={k1:.6f}")
                else:
                    print(f"Invalid global camera parameters for {painting_name}")
                    continue
            else:
                print(f"Invalid global camera parameters format for {painting_name}")
                continue
            
            # Get plane information (use placeholder if not available)
            plane_normal = np.array(plane_data.get('plane_normal', [0, 0, 1]))
            plane_center = np.array(plane_data.get('plane_center', [0, 0, 0]))
            
            # Get image files
            image_files = list(painting_set.glob('*.jpg')) + list(painting_set.glob('*.jpeg')) + list(painting_set.glob('*.png'))
            
            if not image_files:
                print(f"[ERROR] No image files found for {painting_name}")
                continue
            
            # Get camera poses from reconstruction
            images_data = reconstruction_data.get('images', {})
            
            high_res_images = []
            rectification_info = {
                'painting_name': painting_name,
                'num_images': len(image_files),
                'high_res_images': [],
                'roi_bounds': roi_bounds,
                'global_camera_params': global_camera_params,
                'plane_normal': plane_normal.tolist(),
                'plane_center': plane_center.tolist(),
                'target_resolution': 2048,
                'timestamp': datetime.now().isoformat()
            }
            
            for i, image_file in enumerate(image_files):
                print(f"Processing image {i+1}/{len(image_files)}: {image_file.name}")
                
                # Find pose data for this image
                pose_data = None
                for img_id, img_data in images_data.items():
                    if img_data.get('name') == image_file.name:
                        pose_data = img_data.get('pose')
                        break
                
                if not pose_data:
                    print(f"No pose data found for {image_file.name}")
                    continue
                
                # High resolution rectification
                rectified = self.rectify_image_high_res(
                    image_file, pose_data, K, plane_normal, plane_center, 
                    roi_bounds, painting_name, target_resolution=2048
                )
                
                if rectified is not None:
                    # Apply enhancement (rectified already has alpha channel)
                    enhanced = self.apply_enhancement(rectified)
                    
                    # Save high resolution rectified image with alpha channel as PNG
                    output_path = self.high_res_dir / f"{painting_name}_{image_file.stem}_high_res.png"
                    cv2.imwrite(str(output_path), enhanced)
                    print(f"Saved high res rectified image: {output_path.name}")
                    
                    high_res_images.append(enhanced)
                    
                    # Add to rectification info
                    rectification_info['high_res_images'].append({
                        'original_image': image_file.name,
                        'high_res_image': output_path.name,
                        'image_index': i,
                        'resolution': enhanced.shape[:2]
                    })
            
            if not high_res_images:
                print(f"[ERROR] No images could be high-res rectified for {painting_name}")
                continue
            
            high_res_results[painting_name] = rectification_info
            
            # Save intermediate results
            self.save_result(f"high_res_rectification_data_{painting_name}", rectification_info)
            
            print(f"[OK] High resolution rectification completed for {painting_name}")
        
        # Save combined results
        step_results = {
            'high_res_results': high_res_results,
            'global_camera_params': global_camera_params,
            'num_paintings': len(high_res_results),
            'timestamp': datetime.now().isoformat()
        }
        
        self.save_result("step7_high_res_rectification_results", step_results)
        
        print(f"[OK] Step 7 completed. High resolution rectification for {len(high_res_results)} paintings.")
        
        return step_results


if __name__ == "__main__":
    # Test the step independently
    step = HighResRectificationStep()
    results = step.run()
    if results:
        print(f"Step 7 completed. High resolution rectification for {results['num_paintings']} paintings.") 