"""
Step 7: Generate high resolution orthorectified images for ROI using true orthorectification
"""

import cv2
import numpy as np
from pathlib import Path
from datetime import datetime
from step_base import StepBase
import config
import pycolmap
from camera_utils import CameraProjector, PlaneProjector, create_rectification_grid, rectify_image_true_ortho_global


class HighResRectificationStep(StepBase):
    """Step 7: High resolution true orthorectification for ROI"""
    
    def __init__(self, photos_dir=config.PHOTOS_DIR, output_dir=config.OUTPUT_DIR):
        super().__init__(output_dir)
        self.photos_dir = Path(photos_dir)
        self.painting_sets = [d for d in self.photos_dir.iterdir() if d.is_dir()]
        self.high_res_dir = self.output_dir / 'high_res_rectified'
        self.high_res_dir.mkdir(exist_ok=True)
    
    def get_input_requirements(self):
        """Return required inputs for this step"""
        return [
            "step3_recalculate_positions_results",
            "step4_point_cloud_results",
            "step6_roi_selection_results"
        ]
    
    def get_output_files(self):
        """Return output files generated by this step"""
        outputs = []
        for painting_set in self.painting_sets:
            painting_name = painting_set.name
            outputs.extend([
                f"high_res_rectified/{painting_name}_high_res_*.png",
                f"intermediate/high_res_rectification_data_{painting_name}.json"
            ])
        outputs.append("intermediate/step7_high_res_rectification_results.json")
        return outputs

    
    def rectify_image_high_res_roi_global(self, image_path, pose_data, camera_projector, 
                                         plane_projector, global_roi_grid_points_3d, 
                                         target_resolution, painting_name, grid_info):
        """High resolution true orthorectification for ROI area using global grid with proper cropping"""
        img = cv2.imread(str(image_path))
        if img is None: 
            print(f"Could not load image: {image_path}")
            return None
        if not pose_data: 
            print(f"No pose data for: {image_path}")
            return None
        
        # Get camera pose
        R = np.array(pose_data['rotation_matrix'])
        t = np.array(pose_data['translation'])
        
        # Initialize output image with proper dimensions based on grid_info
        grid_width = grid_info['grid_width']
        grid_height = grid_info['grid_height']
        
        # Create output image with the actual ROI dimensions
        rectified = np.zeros((grid_height, grid_width, 3), dtype=np.uint8)
        valid_samples = 0
        total_projections = 0
        
        # For shape-aware grids, we need to create a proper mapping
        # Since we only have the valid points, we'll create a simple linear mapping
        if len(global_roi_grid_points_3d) > 0:
            # Create a mapping from grid index to output coordinates
            # We'll use a simple approach: map the points linearly to the output grid
            points_per_row = max(1, len(global_roi_grid_points_3d) // grid_height)
            
            # Process each 3D point in the ROI grid
            for idx, point_3d_world in enumerate(global_roi_grid_points_3d):
                # Transform world point to camera coordinates
                point_cam = R @ point_3d_world + t
                
                # Project to image coordinates
                point_2d = camera_projector.project_point(point_cam)
                total_projections += 1
                
                if point_2d is not None:
                    x, y = point_2d
                    
                    # Check if point is within image bounds
                    if 0 <= x < img.shape[1] and 0 <= y < img.shape[0]:
                        # Bilinear interpolation
                        x0, y0 = int(x), int(y)
                        x1, y1 = min(x0 + 1, img.shape[1] - 1), min(y0 + 1, img.shape[0] - 1)
                        
                        # Calculate interpolation weights
                        wx = x - x0
                        wy = y - y0
                        
                        # Sample pixels
                        p00 = img[y0, x0].astype(np.float32)
                        p01 = img[y0, x1].astype(np.float32)
                        p10 = img[y1, x0].astype(np.float32)
                        p11 = img[y1, x1].astype(np.float32)
                        
                        # Interpolate
                        pixel_value = (p00 * (1 - wx) * (1 - wy) + 
                                     p01 * wx * (1 - wy) + 
                                     p10 * (1 - wx) * wy + 
                                     p11 * wx * wy)
                        
                        # Map to output coordinates
                        output_i = idx // points_per_row
                        output_j = idx % points_per_row
                        
                        if 0 <= output_i < grid_height and 0 <= output_j < grid_width:
                            rectified[output_i, output_j] = pixel_value.astype(np.uint8)
                            valid_samples += 1
        
        print(f"Rectification stats: {valid_samples}/{total_projections} valid projections, {valid_samples} valid samples")
        
        if valid_samples > 0:
            mean_value = np.mean(rectified)
            print(f"High-res rectified image mean value: {mean_value:.2f}")
            if mean_value < 10: 
                print(f"WARNING: High-res rectified image is very dark (mean={mean_value:.2f})")
            return rectified
        else:
            print(f"WARNING: No valid samples for {image_path}")
            return None
    
    def apply_enhancement(self, image):
        """Apply image enhancement for high resolution output"""
        # Check if image has alpha channel (BGRA)
        if len(image.shape) == 3 and image.shape[2] == 4:
            # Extract BGR channels for enhancement
            bgr = image[:, :, :3]
            alpha = image[:, :, 3]
            
            # Convert to LAB color space
            lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)
            
            # Apply CLAHE to L channel
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            lab[:, :, 0] = clahe.apply(lab[:, :, 0])
            
            # Convert back to BGR
            enhanced_bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
            
            # Apply sharpening
            kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])
            enhanced_bgr = cv2.filter2D(enhanced_bgr, -1, kernel)
            
            # Reconstruct BGRA image
            enhanced = np.zeros((image.shape[0], image.shape[1], 4), dtype=np.uint8)
            enhanced[:, :, :3] = enhanced_bgr
            enhanced[:, :, 3] = alpha
            
            return enhanced
        else:
            # Handle regular BGR images
            # Convert to LAB color space
            lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
            
            # Apply CLAHE to L channel
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            lab[:, :, 0] = clahe.apply(lab[:, :, 0])
            
            # Convert back to BGR
            enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
            
            # Apply sharpening
            kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])
            enhanced = cv2.filter2D(enhanced, -1, kernel)
            
            return enhanced
    
    def run(self, **kwargs):
        """
        Generate high resolution orthorectified images for ROI using true orthorectification.
        
        Returns:
            dict: Results containing high resolution rectification data
        """
        self.log_step("Step 7: High resolution true orthorectification for ROI")
        
        # Load global reconstructions from Step 3
        step3_results = self.load_result("step3_recalculate_positions_results")
        if not step3_results:
            print("[ERROR] Step 3 results not found. Please run Step 3 first.")
            return None
        
        global_reconstructions = step3_results.get('global_reconstructions', {})
        global_camera_params = step3_results.get('global_camera_params')
        
        if not global_reconstructions:
            print("[ERROR] No global reconstructions found in Step 3 results.")
            return None
        
        # Load point cloud data from Step 4
        step4_results = self.load_result("step4_point_cloud_results")
        if not step4_results:
            print("[ERROR] Step 4 results not found. Please run Step 4 first.")
            return None
        
        point_cloud_data = step4_results.get('point_cloud_data', {})
        
        # Load ROI selections from Step 6
        step6_results = self.load_result("step6_roi_selection_results")
        if not step6_results:
            print("[ERROR] Step 6 results not found. Please run Step 6 first.")
            return None
        
        roi_selections = step6_results.get('roi_selections', {})
        
        high_res_results = {}
        
        for painting_set in self.painting_sets:
            painting_name = painting_set.name
            print(f"\n{'='*80}")
            print(f"High resolution true orthorectification for painting {painting_name}")
            print(f"{'='*80}")
            
            # Check if we already have high res rectification data
            existing_result = self.load_result(f"high_res_rectification_data_{painting_name}")
            if existing_result and config.INTERMEDIATE_RESULTS['save_intermediate'] and not self.should_overwrite_existing():
                print(f"Found existing high res rectification data for {painting_name}")
                high_res_results[painting_name] = existing_result
                continue
            
            # Get reconstruction data
            reconstruction_data = global_reconstructions.get(painting_name)
            if not reconstruction_data:
                print(f"[ERROR] No reconstruction data found for {painting_name}")
                continue
            
            # Get point cloud data for plane information
            point_cloud_info = point_cloud_data.get(painting_name, {})
            plane_data = point_cloud_info.get('plane_data', {})
            
            # Get ROI selection
            roi_data = roi_selections.get(painting_name)
            if not roi_data:
                print(f"[ERROR] No ROI selection found for {painting_name}")
                continue
            
            roi_bounds_plane = roi_data.get('roi_bounds_plane', {})
            if not roi_bounds_plane:
                print(f"[ERROR] No ROI plane bounds found for {painting_name}")
                continue
            
            # Create camera projector with global calibration
            camera_projector = CameraProjector(global_camera_params)
            
            # Create plane projector ONCE for the entire painting
            plane_normal = np.array(plane_data.get('plane_normal', [0, 0, 1]))
            plane_center = np.array(plane_data.get('plane_center', [0, 0, 0]))
            plane_projector = PlaneProjector(plane_normal, plane_center)
            
            # Get image files
            image_files = list(painting_set.glob('*.jpg')) + list(painting_set.glob('*.jpeg')) + list(painting_set.glob('*.png'))
            
            if not image_files:
                print(f"[ERROR] No image files found for {painting_name}")
                continue
            
            # Get camera poses from reconstruction
            images_data = reconstruction_data.get('images', {})
            
            # Create global high-resolution grid for ROI area ONCE
            target_resolution = config.RECTIFICATION_CONFIG.get('target_resolution', 2048)
            print(f"Creating global high-resolution grid for ROI area: {target_resolution}x{target_resolution}")
            
            # Extract ROI bounds
            u_min = roi_bounds_plane['u_min']
            u_max = roi_bounds_plane['u_max']
            v_min = roi_bounds_plane['v_min']
            v_max = roi_bounds_plane['v_max']
            
            print(f"ROI bounds in plane coordinates: u=[{u_min:.3f}, {u_max:.3f}], v=[{v_min:.3f}, {v_max:.3f}]")
            
            # Get ROI points in plane coordinates for shape-aware grid
            roi_points_plane = roi_data.get('roi_points_plane', [])
            if roi_points_plane:
                print(f"Using {len(roi_points_plane)} ROI points for shape-aware grid")
                # Create shape-aware grid based on ROI points
                global_roi_grid_points_3d, grid_info = self.create_shape_aware_roi_grid(
                    plane_projector, roi_points_plane, target_resolution
                )
            else:
                print("No ROI points found, using rectangular bounds")
                # Fallback to rectangular grid
                global_roi_grid_points_3d, grid_info = self.create_rectangular_roi_grid(
                    plane_projector, roi_bounds_plane, target_resolution
                )
            
            print(f"Created global ROI grid: {len(global_roi_grid_points_3d)} points for {target_resolution}x{target_resolution} resolution")
            
            high_res_images = []
            rectification_info = {
                'painting_name': painting_name,
                'num_images': len(image_files),
                'high_res_images': [],
                'roi_bounds_plane': roi_bounds_plane,
                'global_camera_params': global_camera_params,
                'plane_normal': plane_normal.tolist(),
                'plane_center': plane_center.tolist(),
                'target_resolution': target_resolution,
                'timestamp': datetime.now().isoformat()
            }
            
            for i, image_file in enumerate(image_files):
                print(f"Processing image {i+1}/{len(image_files)}: {image_file.name}")
                
                # Find pose data for this image
                pose_data = None
                for img_id, img_data in images_data.items():
                    if img_data.get('name') == image_file.name:
                        pose_data = img_data.get('pose')
                        break
                
                if not pose_data:
                    print(f"No pose data found for {image_file.name}")
                    continue
                
                # High resolution true orthorectification for ROI using global grid
                rectified = self.rectify_image_high_res_roi_global(
                    image_file, pose_data, camera_projector, plane_projector, 
                    global_roi_grid_points_3d, target_resolution, painting_name, grid_info
                )
                
                if rectified is not None:
                    # Apply enhancement
                    enhanced = self.apply_enhancement(rectified)
                    
                    # Save high resolution rectified image
                    output_path = self.high_res_dir / f"{painting_name}_{image_file.stem}_high_res.png"
                    cv2.imwrite(str(output_path), enhanced)
                    print(f"Saved high res rectified image: {output_path.name}")
                    
                    high_res_images.append(enhanced)
                    
                    # Add to rectification info
                    rectification_info['high_res_images'].append({
                        'original_image': image_file.name,
                        'high_res_image': output_path.name,
                        'image_index': i,
                        'resolution': enhanced.shape[:2]
                    })
            
            if not high_res_images:
                print(f"[ERROR] No images could be high-res rectified for {painting_name}")
                continue
            
            high_res_results[painting_name] = rectification_info
            
            # Save intermediate results
            self.save_result(f"high_res_rectification_data_{painting_name}", rectification_info)
            
            print(f"[OK] High resolution true orthorectification completed for {painting_name}")
            print(f"  ROI plane bounds: {roi_bounds_plane}")
            print(f"  Target resolution: {target_resolution}x{target_resolution}")
        
        # Save combined results
        step_results = {
            'high_res_results': high_res_results,
            'global_camera_params': global_camera_params,
            'num_paintings': len(high_res_results),
            'timestamp': datetime.now().isoformat()
        }
        
        self.save_result("step7_high_res_rectification_results", step_results)
        
        print(f"[OK] Step 7 completed. High resolution true orthorectification for {len(high_res_results)} paintings.")
        
        return step_results

    def create_shape_aware_roi_grid(self, plane_projector, roi_points_plane, target_resolution):
        """
        Create shape-aware grid that follows the actual ROI boundaries
        
        Args:
            plane_projector: Plane projector instance
            roi_points_plane: ROI points in plane coordinates (u, v)
            target_resolution: Target resolution for output image
            
        Returns:
            Tuple of (grid_points_3d, grid_info) where grid_info contains cropping information
        """
        if len(roi_points_plane) < 3:
            print("Not enough ROI points for shape-aware grid, using rectangular")
            return self.create_rectangular_roi_grid(plane_projector, 
                {'u_min': min(p[0] for p in roi_points_plane), 'u_max': max(p[0] for p in roi_points_plane),
                 'v_min': min(p[1] for p in roi_points_plane), 'v_max': max(p[1] for p in roi_points_plane)}, 
                target_resolution)
        
        # Convert ROI points to numpy array
        roi_points = np.array(roi_points_plane)
        
        # Find bounding box of ROI
        u_min, v_min = roi_points.min(axis=0)
        u_max, v_max = roi_points.max(axis=0)
        
        # Create a dense grid to sample the ROI area
        # We'll create a grid that covers the ROI bounding box
        u_range = u_max - u_min
        v_range = v_max - v_min
        
        # Determine grid density based on target resolution
        # We want to ensure we have enough points to achieve the target resolution
        grid_density = max(target_resolution, int(max(u_range, v_range) * 50))  # At least 50 points per unit
        
        # Create dense sampling grid
        grid_points_3d = []
        valid_indices = []  # Store indices of valid points for cropping
        valid_points = 0
        
        for i in range(grid_density):
            for j in range(grid_density):
                # Map grid coordinates to bounding box coordinates
                u = u_min + (i / (grid_density - 1)) * u_range
                v = v_min + (j / (grid_density - 1)) * v_range
                
                # Check if point is inside ROI polygon
                point_2d = np.array([u, v])
                if self.is_point_inside_polygon(point_2d, roi_points):
                    # Convert to 3D world coordinates
                    point_3d = plane_projector.plane_2d_to_world(point_2d)
                    grid_points_3d.append(point_3d)
                    valid_indices.append((i, j))
                    valid_points += 1
        
        grid_points_3d = np.array(grid_points_3d)
        
        # Calculate cropping information
        if valid_indices:
            valid_indices = np.array(valid_indices)
            min_i, min_j = valid_indices.min(axis=0)
            max_i, max_j = valid_indices.max(axis=0)
            
            # Calculate the actual ROI bounds in grid coordinates
            grid_bounds = {
                'min_i': min_i, 'max_i': max_i,
                'min_j': min_j, 'max_j': max_j,
                'grid_width': max_i - min_i + 1,
                'grid_height': max_j - min_j + 1,
                'total_points': len(grid_points_3d)
            }
        else:
            grid_bounds = {
                'min_i': 0, 'max_i': 0,
                'min_j': 0, 'max_j': 0,
                'grid_width': 1, 'grid_height': 1,
                'total_points': 0
            }
        
        print(f"Shape-aware grid: {valid_points} points inside ROI, grid bounds: {grid_bounds['grid_width']}x{grid_bounds['grid_height']}")
        
        return grid_points_3d, grid_bounds
    
    def create_rectangular_roi_grid(self, plane_projector, roi_bounds_plane, target_resolution):
        """
        Create rectangular grid for ROI area (fallback method)
        
        Args:
            plane_projector: Plane projector instance
            roi_bounds_plane: ROI bounds in painting plane coordinates
            target_resolution: Target resolution for output image
            
        Returns:
            Tuple of (grid_points_3d, grid_info) where grid_info contains cropping information
        """
        # Extract ROI bounds
        u_min = roi_bounds_plane['u_min']
        u_max = roi_bounds_plane['u_max']
        v_min = roi_bounds_plane['v_min']
        v_max = roi_bounds_plane['v_max']
        
        # Create rectangular grid for ROI area
        grid_points_3d = []
        for i in range(target_resolution):
            for j in range(target_resolution):
                # Map grid coordinates to ROI plane coordinates
                u = u_min + (i / (target_resolution - 1)) * (u_max - u_min)
                v = v_min + (j / (target_resolution - 1)) * (v_max - v_min)
                
                # Convert to 3D world coordinates
                point_3d = plane_projector.plane_2d_to_world(np.array([u, v]))
                grid_points_3d.append(point_3d)
        
        grid_points_3d = np.array(grid_points_3d)
        
        # For rectangular grid, the bounds are the full grid
        grid_bounds = {
            'min_i': 0, 'max_i': target_resolution - 1,
            'min_j': 0, 'max_j': target_resolution - 1,
            'grid_width': target_resolution,
            'grid_height': target_resolution,
            'total_points': len(grid_points_3d)
        }
        
        return grid_points_3d, grid_bounds
    
    def is_point_inside_polygon(self, point, polygon):
        """
        Check if a point is inside a polygon using ray casting algorithm
        
        Args:
            point: 2D point [x, y]
            polygon: Array of polygon vertices [[x1, y1], [x2, y2], ...]
            
        Returns:
            True if point is inside polygon
        """
        x, y = point
        n = len(polygon)
        inside = False
        
        p1x, p1y = polygon[0]
        for i in range(n + 1):
            p2x, p2y = polygon[i % n]
            if y > min(p1y, p2y):
                if y <= max(p1y, p2y):
                    if x <= max(p1x, p2x):
                        if p1y != p2y:
                            xinters = (y - p1y) * (p2x - p1x) / (p2y - p1y) + p1x
                        if p1x == p2x or x <= xinters:
                            inside = not inside
            p1x, p1y = p2x, p2y
        
        return inside


if __name__ == "__main__":
    # Test the step independently
    step = HighResRectificationStep()
    results = step.run()
    if results:
        print(f"Step 7 completed. High resolution true orthorectification for {results['num_paintings']} paintings.") 